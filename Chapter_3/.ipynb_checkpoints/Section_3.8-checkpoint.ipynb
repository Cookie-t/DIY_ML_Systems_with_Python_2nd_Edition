{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "train = pd.read_csv('datasets/fashionmnist/fashion-mnist_train.csv')\n",
    "\n",
    "\n",
    "y_train = train['label'].values\n",
    "\n",
    "X_train = train.drop('label', axis=1)\n",
    "\n",
    "mm_scaler = MinMaxScaler(feature_range=(0,1))\n",
    "X_train = mm_scaler.fit_transform(X_train)\n",
    "real_samples, dim = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michael/anaconda/lib/python2.7/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "BATCH_SIZE = 256\n",
    "N_BATCHES = real_samples / BATCH_SIZE\n",
    "N_EPOCHS = 500\n",
    "LEARNING_RATE = 1e-4\n",
    "REAL_INPUT_UNITS = 784\n",
    "HIDDEN_UNITS = 256\n",
    "NOISE_INPUT_UNITS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(noise_img, hidden_units, output_dim, reuse=False):\n",
    "    with tf.variable_scope('generator', reuse=reuse):\n",
    "        hidden_layer = tf.layers.dense(noise_img, hidden_units, activation=tf.nn.relu)\n",
    "        outputs = tf.layers.dense(hidden_layer, output_dim, activation=tf.nn.sigmoid)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(img, hidden_units, reuse=False):\n",
    "    with tf.variable_scope('discriminator', reuse=reuse):\n",
    "        hidden_layer = tf.layers.dense(img, hidden_units, activation=tf.nn.relu)\n",
    "        logits = tf.layers.dense(hidden_layer, 1, activation=None)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def view_samples(epoch, samples):\n",
    "    \"\"\"\n",
    "    epoch代表第几次迭代的图像\n",
    "    samples为我们的采样结果\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(figsize=(7,7), nrows=5, ncols=5, sharey=True, sharex=True)\n",
    "    for ax, img in zip(axes.flatten(), samples[epoch][1]): # 这里samples[epoch][1]代表生成的图像结果，而[0]代表对应的logits\n",
    "        ax.xaxis.set_visible(False)\n",
    "        ax.yaxis.set_visible(False)\n",
    "        im = ax.imshow(img.reshape((28,28)), cmap='Greys_r')\n",
    "    \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0741238, 0.022537675, 4.3083687]\n",
      "[0.08437879, 0.041815907, 3.4732308]\n",
      "[0.089822486, 0.055426642, 3.112172]\n",
      "[0.11118397, 0.05845301, 3.234321]\n",
      "[0.10792889, 0.10484376, 2.5680623]\n",
      "[0.08128883, 0.087131925, 2.6430051]\n",
      "[0.10938832, 0.08681829, 2.6718419]\n",
      "[0.07891975, 0.093123645, 2.640039]\n",
      "[0.15412587, 0.09691031, 2.5665336]\n",
      "[0.19545254, 0.14866099, 2.0862744]\n",
      "[0.154102, 0.13359813, 2.1905215]\n",
      "[0.18149671, 0.1682612, 2.024374]\n",
      "[0.21828008, 0.18260597, 1.9264271]\n",
      "[0.25179836, 0.1906893, 1.8805935]\n",
      "[0.22568087, 0.18845314, 1.9146974]\n",
      "[0.25529993, 0.18798609, 2.0270827]\n",
      "[0.29442328, 0.16706061, 2.131192]\n",
      "[0.29804286, 0.15535566, 2.2783926]\n",
      "[0.2790554, 0.18971318, 2.0504284]\n",
      "[0.25962836, 0.18657848, 2.0813084]\n",
      "[0.21915445, 0.14792946, 2.3374062]\n",
      "[0.26222485, 0.20211488, 2.1558154]\n",
      "[0.23597498, 0.1696017, 2.3994045]\n",
      "[0.28776, 0.17677192, 2.2995992]\n",
      "[0.27811384, 0.1609714, 2.3534565]\n",
      "[0.33377007, 0.18435378, 2.296144]\n",
      "[0.27544385, 0.14606348, 2.4729319]\n",
      "[0.3374756, 0.2569212, 1.8873917]\n",
      "[0.47094473, 0.21776596, 2.0347664]\n",
      "[0.4092478, 0.23966983, 2.0046368]\n",
      "[0.3206916, 0.20386687, 2.402305]\n",
      "[0.33349872, 0.23153755, 2.0164077]\n",
      "[0.35780543, 0.17946011, 2.1408553]\n",
      "[0.2937153, 0.20184383, 2.2088637]\n",
      "[0.22595832, 0.13943215, 2.5090353]\n",
      "[0.23142949, 0.15525453, 2.3774357]\n",
      "[0.20082244, 0.15050381, 2.4118624]\n",
      "[0.19243614, 0.12688391, 2.3515077]\n",
      "[0.11964598, 0.13542485, 2.5341685]\n",
      "[0.27799, 0.1137897, 2.6751795]\n",
      "[0.21567109, 0.15909436, 2.256112]\n",
      "[0.2090807, 0.09058826, 2.7572868]\n",
      "[0.21606456, 0.14011088, 2.2769394]\n",
      "[0.2266753, 0.14441893, 2.5171545]\n",
      "[0.2582432, 0.14651644, 2.5631838]\n",
      "[0.27481788, 0.1538464, 2.1935496]\n",
      "[0.23159274, 0.1579276, 2.1271553]\n",
      "[0.20339793, 0.13521338, 2.3814077]\n",
      "[0.28395897, 0.15244266, 2.4860826]\n",
      "[0.17127264, 0.16486406, 2.241835]\n",
      "[0.32732874, 0.15564892, 2.2854462]\n",
      "[0.20201844, 0.17615776, 2.249951]\n",
      "[0.26279858, 0.153461, 2.1074648]\n",
      "[0.25569862, 0.15576412, 2.2777057]\n",
      "[0.3290104, 0.15584993, 2.3011684]\n",
      "[0.29109773, 0.16673607, 2.2872086]\n",
      "[0.27082413, 0.16903313, 2.2081633]\n",
      "[0.3007304, 0.23396729, 1.8897002]\n",
      "[0.30941433, 0.19382417, 2.0179014]\n",
      "[0.50919896, 0.18087184, 2.086502]\n",
      "[0.3347224, 0.20943353, 2.024972]\n",
      "[0.4519421, 0.21874762, 1.9878712]\n",
      "[0.38434407, 0.30992004, 1.7426269]\n",
      "[0.44146347, 0.21188203, 1.9754928]\n",
      "[0.45430657, 0.3121463, 1.6605226]\n",
      "[0.4785896, 0.26658905, 1.8438199]\n",
      "[0.7169504, 0.27983305, 1.6457295]\n",
      "[0.478935, 0.23214453, 1.9188074]\n",
      "[0.59268594, 0.2682367, 1.8469019]\n",
      "[0.60773695, 0.34747368, 1.5988197]\n",
      "[0.51484376, 0.25438178, 1.7493881]\n",
      "[0.5539745, 0.22591361, 2.1657825]\n",
      "[0.6152141, 0.3381097, 1.7936556]\n",
      "[0.56239605, 0.32294214, 2.007252]\n",
      "[0.6534791, 0.32350773, 1.8918046]\n",
      "[0.6652317, 0.34056225, 2.045326]\n",
      "[0.49734488, 0.30972502, 2.0334625]\n",
      "[0.5894052, 0.30067933, 2.1206074]\n",
      "[0.505377, 0.26336947, 1.9634964]\n",
      "[0.6466917, 0.2736025, 1.9985012]\n",
      "[0.4192689, 0.30785626, 2.0849705]\n",
      "[0.3475621, 0.2610343, 2.0262718]\n",
      "[0.5869321, 0.23069431, 2.0075123]\n",
      "[0.62707233, 0.23605849, 2.0223184]\n",
      "[0.5271572, 0.18403193, 2.1916955]\n",
      "[0.5575488, 0.26455107, 2.1142898]\n",
      "[0.41701996, 0.27169535, 1.9219317]\n",
      "[0.52262443, 0.23157763, 2.2357268]\n",
      "[0.44482148, 0.2652279, 1.9049625]\n",
      "[0.54265165, 0.28501433, 1.9805362]\n",
      "[0.4990211, 0.24584013, 2.0304923]\n",
      "[0.5446029, 0.25225738, 2.14638]\n",
      "[0.41187197, 0.18568203, 2.315207]\n",
      "[0.56961393, 0.23957771, 2.072247]\n",
      "[0.59647095, 0.2384892, 2.0803428]\n",
      "[0.48634762, 0.21571173, 2.0214524]\n",
      "[0.485057, 0.25292468, 2.1551762]\n",
      "[0.5588726, 0.2975722, 1.7489169]\n",
      "[0.37931025, 0.35434902, 1.7895007]\n",
      "[0.58231294, 0.24550186, 1.9765239]\n",
      "[0.6266773, 0.31236452, 1.9249059]\n",
      "[0.5848751, 0.21588005, 2.208717]\n",
      "[0.5665757, 0.305803, 1.7728376]\n",
      "[0.48927, 0.26473612, 1.8511708]\n",
      "[0.52959204, 0.24482131, 2.1911478]\n",
      "[0.4802586, 0.28879154, 1.7739962]\n",
      "[0.48478967, 0.23639008, 1.9840776]\n",
      "[0.5125481, 0.20629242, 2.0330453]\n",
      "[0.6068167, 0.3116408, 1.8114941]\n",
      "[0.65420055, 0.20432895, 2.0605974]\n",
      "[0.5493033, 0.2933642, 1.7370915]\n",
      "[0.6008793, 0.34614837, 1.6927047]\n",
      "[0.5324406, 0.26230752, 1.7571809]\n",
      "[0.6008189, 0.23933214, 2.1296904]\n",
      "[0.707783, 0.33231783, 1.8176502]\n",
      "[0.65775406, 0.28546405, 1.845648]\n",
      "[0.5028863, 0.2959497, 2.0040245]\n",
      "[0.44720647, 0.26746133, 1.8968521]\n",
      "[0.6089469, 0.28776467, 2.009576]\n",
      "[0.66657114, 0.26386863, 1.8076826]\n",
      "[0.6570616, 0.25209236, 2.0810528]\n",
      "[0.5233294, 0.24630056, 1.8104023]\n",
      "[0.5063245, 0.33406305, 1.9219611]\n",
      "[0.3768344, 0.33669612, 2.0299833]\n",
      "[0.71942794, 0.3946765, 2.2564735]\n",
      "[0.4034369, 0.38465148, 1.9478395]\n",
      "[0.5143446, 0.38631147, 1.819674]\n",
      "[0.65824926, 0.36880913, 1.5837038]\n",
      "[0.5486621, 0.25914022, 1.8217747]\n",
      "[0.7098938, 0.3237837, 1.6929367]\n",
      "[0.6042878, 0.30349773, 1.8087604]\n",
      "[0.5439741, 0.3584116, 1.6352584]\n",
      "[0.49783203, 0.32471183, 1.895189]\n",
      "[0.43480134, 0.32277852, 1.73792]\n",
      "[0.829919, 0.3468776, 1.6260158]\n",
      "[0.60359216, 0.31891218, 1.6775895]\n",
      "[0.6082486, 0.31145108, 1.6574813]\n",
      "[0.5721693, 0.25921988, 1.7745051]\n",
      "[0.5569476, 0.3140049, 1.610369]\n",
      "[0.50023323, 0.31791604, 1.6123137]\n",
      "[0.5457794, 0.2844409, 1.8085588]\n",
      "[0.5079713, 0.3205856, 1.6926608]\n",
      "[0.64556396, 0.36381483, 1.6422611]\n",
      "[0.5921954, 0.27497846, 2.016498]\n",
      "[0.5395459, 0.2630624, 1.8575011]\n",
      "[0.68641055, 0.3316699, 1.9167092]\n",
      "[0.5284393, 0.3498061, 1.7039933]\n",
      "[0.56632674, 0.22534303, 2.064989]\n",
      "[0.7275903, 0.21310343, 2.1058536]\n",
      "[0.61478317, 0.2544807, 1.9919157]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-212b821e17b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mbatch_real_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m             \u001b[0mbatch_noise_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNOISE_INPUT_UNITS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "real_img = tf.placeholder(tf.float32, [None, REAL_INPUT_UNITS], name='real_img')\n",
    "noise_img = tf.placeholder(tf.float32, [None, NOISE_INPUT_UNITS], name='noise_img')\n",
    "\n",
    "gen_outputs = generator(noise_img, HIDDEN_UNITS, REAL_INPUT_UNITS)\n",
    "\n",
    "dis_real_logits = discriminator(real_img, HIDDEN_UNITS)\n",
    "dis_fake_logits = discriminator(gen_outputs, HIDDEN_UNITS, reuse=True)\n",
    "\n",
    "dis_real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=dis_real_logits, labels=tf.ones_like(dis_real_logits)))\n",
    "dis_fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=dis_fake_logits, labels=tf.zeros_like(dis_fake_logits)))                           \n",
    "dis_loss = dis_real_loss + dis_fake_loss\n",
    "\n",
    "gen_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=dis_fake_logits, labels=tf.ones_like(dis_fake_logits)))\n",
    "\n",
    "train_vars = tf.trainable_variables()\n",
    "\n",
    "dis_vars = [var for var in train_vars if var.name.startswith('discriminator')]\n",
    "dis_train_opt = tf.train.AdamOptimizer(LEARNING_RATE).minimize(dis_loss, var_list=dis_vars)\n",
    "\n",
    "gen_vars = [var for var in train_vars if var.name.startswith('generator')]\n",
    "gen_train_opt = tf.train.AdamOptimizer(LEARNING_RATE).minimize(gen_loss, var_list=gen_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for iteration in range(N_EPOCHS):\n",
    "        for i in range(N_BATCHES):\n",
    "            np.random.seed(iteration * N_BATCHES + i)\n",
    "            \n",
    "            indices = np.random.randint(real_samples, size=BATCH_SIZE)\n",
    "            \n",
    "            batch_real_imgs = X_train[indices]\n",
    "            batch_noise_imgs = np.random.uniform(-1, 1, size=(BATCH_SIZE, NOISE_INPUT_UNITS))\n",
    "            \n",
    "            sess.run(dis_train_opt, feed_dict={real_img: batch_real_imgs, noise_img: batch_noise_imgs})\n",
    "            sess.run(gen_train_opt, feed_dict={noise_img: batch_noise_imgs})\n",
    "            \n",
    "        print sess.run([dis_real_loss, dis_fake_loss, gen_loss], feed_dict={real_img:batch_real_imgs, noise_img: batch_noise_imgs})\n",
    "        #print 'Iteration %d, loss = %f' % (iteration + 1, loss.eval(feed_dict = {X: X_train}))\n",
    "    \n",
    "    sample_noise = np.random.uniform(-1, 1, size=(25, noise_size))\n",
    "    gen_samples = sess.run(gen_outputs,\n",
    "                           feed_dict={noise_img: sample_noise})\n",
    "    _ = view_samples(0, [gen_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
